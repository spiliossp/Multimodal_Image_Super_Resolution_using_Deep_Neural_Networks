{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea53d368-5287-4a3b-8832-8c0de92760a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "\"\"\"\n",
    "LeSITA: Clean Paper-Compliant Implementation\n",
    "===========================================\n",
    "\n",
    "Based on Papers:\n",
    "- Paper 3: Convolutional Sparse Coding with Side Information via Deep Unfolding\n",
    "- Paper 4: Interpretable deep learning for multimodal super-resolution of medical images\n",
    "\n",
    "Features:\n",
    "- ‚úÖ Complete ACSC-LMCSC architecture (Paper 3 & 4)\n",
    "- ‚úÖ Original vs Co-evolving forward modes\n",
    "- ‚úÖ Paper-compliant initialization and training\n",
    "- ‚úÖ Clean menu system for easy usage\n",
    "- ‚úÖ Comprehensive visualization and logging\n",
    "- ‚úÖ No code duplication, clean structure\n",
    "\n",
    "Author: Based on LeSITA Papers - Clean Implementation\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# Style for better plots\n",
    "plt.style.use('default')\n",
    "\n",
    "# =============================================================================\n",
    "# DATA LOADING\n",
    "# =============================================================================\n",
    "\n",
    "class MRIDataset(Dataset):\n",
    "    \"\"\"MRI Dataset Loader for T2W (LR/HR) and T1W (guidance) images\"\"\"\n",
    "    \n",
    "    def __init__(self, h5_file, input_key='T2W/LRINPUT', target_key='T2W/TARGET', \n",
    "                 si_key='T1W/TARGET', augment=False):\n",
    "        self.h5_file = h5_file\n",
    "        with h5py.File(h5_file, 'r') as file:\n",
    "            self.inputs = file[input_key][:]      # LR T2W\n",
    "            self.targets = file[target_key][:]    # HR T2W  \n",
    "            self.si = file[si_key][:]             # HR T1W (guidance)\n",
    "\n",
    "        assert len(self.inputs) == len(self.targets) == len(self.si), \\\n",
    "               \"Mismatch in dataset lengths.\"\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Normalize to [0,1]\n",
    "        input_img = self.inputs[idx].astype(np.float32) / 255.0\n",
    "        target_img = self.targets[idx].astype(np.float32) / 255.0\n",
    "        si_img = self.si[idx].astype(np.float32) / 255.0\n",
    "\n",
    "        # Add channel dimension\n",
    "        input_img = torch.from_numpy(input_img).unsqueeze(0)\n",
    "        target_img = torch.from_numpy(target_img).unsqueeze(0)\n",
    "        si_img = torch.from_numpy(si_img).unsqueeze(0)\n",
    "\n",
    "        # Data augmentation if enabled\n",
    "        if self.augment:\n",
    "            if torch.rand(1) > 0.5:  # Horizontal flip\n",
    "                input_img = torch.flip(input_img, [2])\n",
    "                target_img = torch.flip(target_img, [2])\n",
    "                si_img = torch.flip(si_img, [2])\n",
    "            if torch.rand(1) > 0.5:  # Vertical flip\n",
    "                input_img = torch.flip(input_img, [1])\n",
    "                target_img = torch.flip(target_img, [1])\n",
    "                si_img = torch.flip(si_img, [1])\n",
    "            if torch.rand(1) > 0.5:  # Rotation\n",
    "                k = torch.randint(0, 4, (1,))\n",
    "                input_img = torch.rot90(input_img, k.item(), [1, 2])\n",
    "                target_img = torch.rot90(target_img, k.item(), [1, 2])\n",
    "                si_img = torch.rot90(si_img, k.item(), [1, 2])\n",
    "\n",
    "        return input_img, target_img, si_img\n",
    "\n",
    "def get_dataloader(h5_file, batch_size=32, shuffle=True, augment=False):\n",
    "    \"\"\"Create DataLoader for MRI dataset\"\"\"\n",
    "    dataset = MRIDataset(h5_file, augment=augment)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "# =============================================================================\n",
    "# CORE ACTIVATION FUNCTIONS (Paper 3)\n",
    "# =============================================================================\n",
    "\n",
    "class ShLU(nn.Module):\n",
    "    \"\"\"\n",
    "    Soft Thresholding Operator (œÜŒ≥) from Papers\n",
    "    Equation: œÜŒ≥(vi) = sign(vi) * max{0, |vi| ‚àí Œ≥}\n",
    "    \n",
    "    From Paper 4: \"The initial value of the parameters Œ≥, Œº is set to 0.1\"\n",
    "    \"\"\"\n",
    "    def __init__(self, threshold=0.1):\n",
    "        super(ShLU, self).__init__()\n",
    "        self.threshold = nn.Parameter(torch.tensor(threshold, dtype=torch.float32))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return torch.sign(x) * torch.clamp(torch.abs(x) - self.threshold, min=0.0)\n",
    "\n",
    "class LeSITA(nn.Module):\n",
    "    \"\"\"\n",
    "    LeSITA Proximal Operator (ŒæŒº) from Paper 3\n",
    "    Equations (13) and (14): ŒæŒº(vi; zi) - different behavior for zi ‚â• 0 and zi < 0\n",
    "    \"\"\"\n",
    "    def __init__(self, mu=0.1):\n",
    "        super(LeSITA, self).__init__()\n",
    "        self.mu = nn.Parameter(torch.tensor(mu, dtype=torch.float32))\n",
    "        \n",
    "    def forward(self, u, z):\n",
    "        \"\"\"\n",
    "        u: input tensor (vi in equations)  \n",
    "        z: side information tensor (zi in equations)\n",
    "        \"\"\"\n",
    "        zeros = torch.zeros_like(u)\n",
    "        \n",
    "        # Equation (13): For zi ‚â• 0\n",
    "        output = torch.where((z >= 0) & (u < -2*self.mu), u + 2*self.mu, zeros)\n",
    "        output = torch.where((z >= 0) & (-2*self.mu <= u) & (u <= 0), zeros, output)\n",
    "        output = torch.where((z >= 0) & (0 < u) & (u < z), u, output)\n",
    "        output = torch.where((z >= 0) & (z <= u) & (u <= z + 2*self.mu), z, output)\n",
    "        output = torch.where((z >= 0) & (u > z + 2*self.mu), u - 2*self.mu, output)\n",
    "        \n",
    "        # Equation (14): For zi < 0\n",
    "        output = torch.where((z < 0) & (u < z - 2*self.mu), u + 2*self.mu, output)\n",
    "        output = torch.where((z < 0) & (z - 2*self.mu <= u) & (u <= z), z, output)\n",
    "        output = torch.where((z < 0) & (z < u) & (u < 0), u, output)\n",
    "        output = torch.where((z < 0) & (0 <= u) & (u <= 2*self.mu), zeros, output)\n",
    "        output = torch.where((z < 0) & (u > 2*self.mu), u - 2*self.mu, output)\n",
    "        \n",
    "        return output\n",
    "\n",
    "# =============================================================================\n",
    "# CORE NETWORK MODULES\n",
    "# =============================================================================\n",
    "\n",
    "class ACSC(nn.Module):\n",
    "    \"\"\"\n",
    "    ACSC Model from Papers\n",
    "    Equation (8): Z^t = œÜŒ≥(Z^{t-1} - T * V * Z^{t-1} + G * Œ©)\n",
    "    \"\"\"\n",
    "    def __init__(self, num_stages=3, num_filters=85, kernel_size=7, threshold=0.1):\n",
    "        super(ACSC, self).__init__()\n",
    "        self.num_stages = num_stages\n",
    "        \n",
    "        self.shlu = ShLU(threshold)\n",
    "        self.G = nn.Conv2d(1, num_filters, kernel_size, padding=kernel_size//2)\n",
    "        \n",
    "        self.T_layers = nn.ModuleList([\n",
    "            nn.Conv2d(num_filters, num_filters, kernel_size, padding=kernel_size//2)\n",
    "            for _ in range(num_stages)\n",
    "        ])\n",
    "        \n",
    "        self.V_layers = nn.ModuleList([\n",
    "            nn.Conv2d(num_filters, num_filters, kernel_size, padding=kernel_size//2)\n",
    "            for _ in range(num_stages)\n",
    "        ])\n",
    "        \n",
    "    def forward(self, omega):\n",
    "        \"\"\"Original ACSC forward pass\"\"\"\n",
    "        batch_size, channels, height, width = omega.shape\n",
    "        Z = torch.zeros(batch_size, self.G.out_channels, height, width, \n",
    "                       device=omega.device, dtype=omega.dtype)\n",
    "        \n",
    "        G_omega = self.G(omega)\n",
    "        \n",
    "        for t in range(self.num_stages):\n",
    "            conv_V = self.V_layers[t](Z)\n",
    "            conv_TV = self.T_layers[t](conv_V)\n",
    "            Z = self.shlu(Z - conv_TV + G_omega)\n",
    "            \n",
    "        return Z\n",
    "    \n",
    "    def forward_single_stage(self, Z, omega, stage_idx):\n",
    "        \"\"\"Single stage forward for co-evolving mode\"\"\"\n",
    "        if not hasattr(self, '_cached_G_omega') or stage_idx == 0:\n",
    "            self._cached_G_omega = self.G(omega)\n",
    "        \n",
    "        conv_V = self.V_layers[stage_idx](Z)\n",
    "        conv_TV = self.T_layers[stage_idx](conv_V)\n",
    "        Z = self.shlu(Z - conv_TV + self._cached_G_omega)\n",
    "        \n",
    "        return Z\n",
    "\n",
    "class LMCSC(nn.Module):\n",
    "    \"\"\"\n",
    "    LMCSC Model from Papers\n",
    "    Equation (7): U^t = ŒæŒº(U^{t-1} - Q * R * U^{t-1} + P * Y ; Z)\n",
    "    \"\"\"\n",
    "    def __init__(self, num_stages=3, num_filters=85, kernel_size=7, mu=0.1):\n",
    "        super(LMCSC, self).__init__()\n",
    "        self.num_stages = num_stages\n",
    "        \n",
    "        self.lesita = LeSITA(mu)\n",
    "        self.P = nn.Conv2d(1, num_filters, kernel_size, padding=kernel_size//2)\n",
    "        \n",
    "        self.Q_layers = nn.ModuleList([\n",
    "            nn.Conv2d(num_filters, num_filters, kernel_size, padding=kernel_size//2)\n",
    "            for _ in range(num_stages)\n",
    "        ])\n",
    "        \n",
    "        self.R_layers = nn.ModuleList([\n",
    "            nn.Conv2d(num_filters, num_filters, kernel_size, padding=kernel_size//2)\n",
    "            for _ in range(num_stages)\n",
    "        ])\n",
    "        \n",
    "    def forward(self, Y, Z):\n",
    "        \"\"\"Original LMCSC forward pass\"\"\"\n",
    "        batch_size, channels, height, width = Y.shape\n",
    "        U = torch.zeros(batch_size, self.P.out_channels, height, width,\n",
    "                       device=Y.device, dtype=Y.dtype)\n",
    "        \n",
    "        P_Y = self.P(Y)\n",
    "        \n",
    "        for t in range(self.num_stages):\n",
    "            conv_R = self.R_layers[t](U)\n",
    "            conv_QR = self.Q_layers[t](conv_R)\n",
    "            U = self.lesita(U - conv_QR + P_Y, Z)\n",
    "            \n",
    "        return U\n",
    "\n",
    "    def forward_single_stage(self, U, Y, Z, stage_idx):\n",
    "        \"\"\"Single stage forward for co-evolving mode\"\"\"\n",
    "        if not hasattr(self, '_cached_P_Y') or stage_idx == 0:\n",
    "            self._cached_P_Y = self.P(Y)\n",
    "        \n",
    "        conv_R = self.R_layers[stage_idx](U)\n",
    "        conv_QR = self.Q_layers[stage_idx](conv_R)\n",
    "        U = self.lesita(U - conv_QR + self._cached_P_Y, Z)\n",
    "        \n",
    "        return U\n",
    "\n",
    "class ReconstructionModule(nn.Module):\n",
    "    \"\"\"\n",
    "    Reconstruction Module from Papers\n",
    "    Converts sparse coefficients to HR image\n",
    "    \"\"\"\n",
    "    def __init__(self, num_filters=85, kernel_size=7):\n",
    "        super(ReconstructionModule, self).__init__()\n",
    "        self.dictionary = nn.Conv2d(num_filters, 1, kernel_size, padding=kernel_size//2)\n",
    "        \n",
    "    def forward(self, u):\n",
    "        \"\"\"u: sparse coefficients from LMCSC\"\"\"\n",
    "        # Unit norm constraint for dictionary stability\n",
    "        with torch.no_grad():\n",
    "            weight = self.dictionary.weight\n",
    "            weight_norm = torch.norm(weight.view(weight.size(0), -1), dim=1, keepdim=True)\n",
    "            weight_norm = weight_norm.view(-1, 1, 1, 1)\n",
    "            weight_norm = torch.clamp(weight_norm, min=1e-8)\n",
    "            self.dictionary.weight.data = weight / weight_norm\n",
    "        \n",
    "        return self.dictionary(u)\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN NETWORK\n",
    "# =============================================================================\n",
    "\n",
    "class LMCSCNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    Complete LMCSC Network from Papers\n",
    "    Supports both Original and Co-evolving forward modes\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 num_stages_acsc=3, \n",
    "                 num_stages_lmcsc=3, \n",
    "                 num_filters=85, \n",
    "                 kernel_size=7,\n",
    "                 threshold=0.1,\n",
    "                 mu=0.1):\n",
    "        super(LMCSCNetwork, self).__init__()\n",
    "        \n",
    "        # Paper 4 parameters\n",
    "        self.acsc = ACSC(\n",
    "            num_stages=num_stages_acsc,\n",
    "            num_filters=num_filters, \n",
    "            kernel_size=kernel_size,\n",
    "            threshold=threshold\n",
    "        )\n",
    "        \n",
    "        self.lmcsc = LMCSC(\n",
    "            num_stages=num_stages_lmcsc,\n",
    "            num_filters=num_filters,\n",
    "            kernel_size=kernel_size, \n",
    "            mu=mu\n",
    "        )\n",
    "        \n",
    "        self.reconstruction = ReconstructionModule(\n",
    "            num_filters=num_filters,\n",
    "            kernel_size=kernel_size\n",
    "        )\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialization according to Paper 4\"\"\"\n",
    "        print(\"üîß Initializing LMCSC Network according to Paper 4...\")\n",
    "        \n",
    "        for name, module in self.named_modules():\n",
    "            if isinstance(module, nn.Conv2d):\n",
    "                nn.init.normal_(module.weight, mean=0.0, std=0.01)\n",
    "                if module.bias is not None:\n",
    "                    nn.init.zeros_(module.bias)\n",
    "                \n",
    "            elif isinstance(module, ShLU):\n",
    "                with torch.no_grad():\n",
    "                    module.threshold.data.fill_(0.1)\n",
    "                \n",
    "            elif isinstance(module, LeSITA):\n",
    "                with torch.no_grad():\n",
    "                    module.mu.data.fill_(0.1)\n",
    "        \n",
    "        print(\"‚úÖ Initialization completed according to Paper 4!\")\n",
    "        \n",
    "    def forward(self, y, omega, mode='original'):\n",
    "        \"\"\"\n",
    "        Forward pass with mode selection\n",
    "        \n",
    "        Args:\n",
    "            y: LR target image (T2W)\n",
    "            omega: HR guidance image (T1W)  \n",
    "            mode: 'original' or 'coevolving'\n",
    "        \"\"\"\n",
    "        if mode == 'original':\n",
    "            return self._forward_original(y, omega)\n",
    "        elif mode == 'coevolving':\n",
    "            return self._forward_coevolving(y, omega)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown mode: {mode}. Use 'original' or 'coevolving'\")\n",
    "    \n",
    "    def _forward_original(self, y, omega):\n",
    "        \"\"\"Original forward pass (sequential ACSC then LMCSC)\"\"\"\n",
    "        z = self.acsc(omega)\n",
    "        u = self.lmcsc(y, z)\n",
    "        out = self.reconstruction(u)\n",
    "        return out, u, z\n",
    "\n",
    "    def _forward_coevolving(self, y, omega):\n",
    "        \"\"\"Co-evolving forward pass (simultaneous ACSC and LMCSC)\"\"\"\n",
    "        batch_size, channels, height, width = y.shape\n",
    "        \n",
    "        # Initialize sparse codes\n",
    "        Z = torch.zeros(batch_size, 85, height, width, device=omega.device, dtype=omega.dtype)\n",
    "        U = torch.zeros(batch_size, 85, height, width, device=y.device, dtype=y.dtype)\n",
    "        \n",
    "        # Co-evolving iterations\n",
    "        for stage in range(3):\n",
    "            Z = self.acsc.forward_single_stage(Z, omega, stage)\n",
    "            U = self.lmcsc.forward_single_stage(U, y, Z, stage)\n",
    "        \n",
    "        out = self.reconstruction(U)\n",
    "        return out, U, Z\n",
    "\n",
    "# =============================================================================\n",
    "# METRICS\n",
    "# =============================================================================\n",
    "\n",
    "def psnr(y_true, y_pred, max_val=1.0):\n",
    "    \"\"\"PSNR metric as used in papers\"\"\"\n",
    "    mse = torch.mean((y_true - y_pred) ** 2)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    return 20 * torch.log10(max_val / torch.sqrt(mse))\n",
    "\n",
    "# =============================================================================\n",
    "# TRAINING SYSTEM\n",
    "# =============================================================================\n",
    "\n",
    "class LMCSCTrainer:\n",
    "    \"\"\"Training setup according to Paper 4\"\"\"\n",
    "    \n",
    "    def __init__(self, model, device, mode='original'):\n",
    "        self.model = model.to(device)\n",
    "        self.device = device\n",
    "        self.mode = mode  # 'original' or 'coevolving'\n",
    "        \n",
    "        # Paper 4 training setup\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=1e-4)\n",
    "        \n",
    "        print(f\"üöÄ LMCSCTrainer initialized\")\n",
    "        print(f\"   Mode: {mode}\")\n",
    "        print(f\"   Loss: MSE | Optimizer: Adam (lr=1e-4)\")\n",
    "        print(f\"   Device: {device}\")\n",
    "\n",
    "    def train_epoch(self, dataloader):\n",
    "        \"\"\"Training for one epoch\"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        self.model.train()\n",
    "        total_loss = 0.0\n",
    "        total_psnr = 0.0\n",
    "\n",
    "        for batch_idx, (x_lr, x_hr, x_si) in enumerate(dataloader):\n",
    "            x_lr = x_lr.to(self.device)\n",
    "            x_hr = x_hr.to(self.device)\n",
    "            x_si = x_si.to(self.device)\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass with selected mode\n",
    "            pred_hr, sparse_u, sparse_z = self.model(x_lr, x_si, mode=self.mode)\n",
    "            \n",
    "            loss = self.criterion(pred_hr, x_hr)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                batch_psnr = psnr(x_hr, pred_hr)\n",
    "                total_psnr += batch_psnr.item() if torch.isfinite(batch_psnr) else 0.0\n",
    "        \n",
    "        epoch_time = time.time() - start_time\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        avg_psnr = total_psnr / len(dataloader)\n",
    "        \n",
    "        return avg_loss, avg_psnr, epoch_time\n",
    "    \n",
    "    def validate(self, dataloader):\n",
    "        \"\"\"Validation loop\"\"\"\n",
    "        self.model.eval()\n",
    "        total_loss = 0.0\n",
    "        total_psnr = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for x_lr, x_hr, x_si in dataloader:\n",
    "                x_lr = x_lr.to(self.device)\n",
    "                x_hr = x_hr.to(self.device) \n",
    "                x_si = x_si.to(self.device)\n",
    "\n",
    "                pred_hr, _, _ = self.model(x_lr, x_si, mode=self.mode)\n",
    "                \n",
    "                loss = self.criterion(pred_hr, x_hr)\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                batch_psnr = psnr(x_hr, pred_hr)\n",
    "                total_psnr += batch_psnr.item() if torch.isfinite(batch_psnr) else 0.0\n",
    "        \n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        avg_psnr = total_psnr / len(dataloader)\n",
    "        \n",
    "        return avg_loss, avg_psnr\n",
    "    \n",
    "    def train(self, train_loader, val_loader, epochs=50, save_path=\"lesita_best.pt\"):\n",
    "        \"\"\"Complete training loop\"\"\"\n",
    "        print(f\"\\nüöÄ Starting LeSITA Training ({self.mode.upper()} mode)\")\n",
    "        print(f\"üìä Configuration: {epochs} epochs | Mode: {self.mode}\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        best_psnr = 0.0\n",
    "        training_log = []\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            # Training\n",
    "            train_loss, train_psnr, epoch_time = self.train_epoch(train_loader)\n",
    "            \n",
    "            # Validation\n",
    "            val_loss, val_psnr = self.validate(val_loader)\n",
    "            \n",
    "            # Logging\n",
    "            is_best = val_psnr > best_psnr\n",
    "            if is_best:\n",
    "                best_psnr = val_psnr\n",
    "                # Save best model\n",
    "                torch.save({\n",
    "                    'epoch': epoch + 1,\n",
    "                    'model_state_dict': self.model.state_dict(),\n",
    "                    'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "                    'best_psnr': best_psnr,\n",
    "                    'mode': self.mode,\n",
    "                    'config': {\n",
    "                        'num_stages_acsc': 3,\n",
    "                        'num_stages_lmcsc': 3,\n",
    "                        'num_filters': 85,\n",
    "                        'kernel_size': 7,\n",
    "                        'threshold': 0.1,\n",
    "                        'mu': 0.1\n",
    "                    }\n",
    "                }, save_path)\n",
    "            \n",
    "            # Store training log\n",
    "            training_log.append({\n",
    "                'epoch': epoch + 1,\n",
    "                'train_loss': train_loss,\n",
    "                'train_psnr': train_psnr,\n",
    "                'val_loss': val_loss,\n",
    "                'val_psnr': val_psnr,\n",
    "                'epoch_time': epoch_time,\n",
    "                'is_best': is_best\n",
    "            })\n",
    "            \n",
    "            # Print progress\n",
    "            mode_icon = \"üîÑ\" if self.mode == \"coevolving\" else \"üìò\"\n",
    "            print(f\"{mode_icon} Epoch [{epoch+1:3d}/{epochs}] | \"\n",
    "                  f\"Train: Loss={train_loss:.6f}, PSNR={train_psnr:.2f}dB | \"\n",
    "                  f\"Val: Loss={val_loss:.6f}, PSNR={val_psnr:.2f}dB | \"\n",
    "                  f\"Time: {epoch_time:.1f}s\"\n",
    "                  + (f\" üåü NEW BEST!\" if is_best else \"\"))\n",
    "        \n",
    "        print(f\"\\n‚úÖ Training completed!\")\n",
    "        print(f\"üèÜ Best validation PSNR: {best_psnr:.2f}dB\")\n",
    "        print(f\"üíæ Model saved: {save_path}\")\n",
    "        \n",
    "        return best_psnr, training_log\n",
    "\n",
    "# =============================================================================\n",
    "# TESTING & EVALUATION\n",
    "# =============================================================================\n",
    "\n",
    "def test_model(model_path, test_loader, device):\n",
    "    \"\"\"Test trained model and return results\"\"\"\n",
    "    print(\"üß™ Starting Model Testing...\")\n",
    "    \n",
    "    # Load model\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    config = checkpoint.get('config', {\n",
    "        'num_stages_acsc': 3, 'num_stages_lmcsc': 3, 'num_filters': 85,\n",
    "        'kernel_size': 7, 'threshold': 0.1, 'mu': 0.1\n",
    "    })\n",
    "    \n",
    "    model = LMCSCNetwork(**config).to(device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    \n",
    "    mode = checkpoint.get('mode', 'original')\n",
    "    best_psnr = checkpoint.get('best_psnr', 0.0)\n",
    "    \n",
    "    print(f\"üìÇ Loaded model: {model_path}\")\n",
    "    print(f\"üéØ Mode: {mode} | Best training PSNR: {best_psnr:.2f}dB\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Testing\n",
    "    total_psnr = 0.0\n",
    "    total_samples = 0\n",
    "    results = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (x_lr, x_hr, x_si) in enumerate(test_loader):\n",
    "            x_lr = x_lr.to(device)\n",
    "            x_hr = x_hr.to(device)\n",
    "            x_si = x_si.to(device)\n",
    "            \n",
    "            # Inference with original model mode\n",
    "            pred_hr, sparse_u, sparse_z = model(x_lr, x_si, mode=mode)\n",
    "            \n",
    "            # Calculate PSNR for each image\n",
    "            for i in range(x_lr.shape[0]):\n",
    "                img_psnr = psnr(x_hr[i:i+1], pred_hr[i:i+1]).item()\n",
    "                total_psnr += img_psnr\n",
    "                total_samples += 1\n",
    "                \n",
    "                # Store first 5 for visualization\n",
    "                if len(results) < 5:\n",
    "                    results.append({\n",
    "                        'lr': x_lr[i].cpu(),\n",
    "                        'hr_gt': x_hr[i].cpu(), \n",
    "                        'hr_pred': pred_hr[i].cpu(),\n",
    "                        'guidance': x_si[i].cpu(),\n",
    "                        'sparse_u': sparse_u[i].cpu(),\n",
    "                        'sparse_z': sparse_z[i].cpu(),\n",
    "                        'psnr': img_psnr\n",
    "                    })\n",
    "            \n",
    "            if batch_idx % 5 == 0:\n",
    "                print(f\"   Processed batch {batch_idx+1}/{len(test_loader)}\")\n",
    "    \n",
    "    avg_psnr = total_psnr / total_samples\n",
    "    print(f\"\\nüìä RESULTS:\")\n",
    "    print(f\"   Average PSNR: {avg_psnr:.2f}dB\")\n",
    "    print(f\"   Total samples: {total_samples}\")\n",
    "    \n",
    "    return results, avg_psnr\n",
    "\n",
    "# =============================================================================\n",
    "# VISUALIZATION\n",
    "# =============================================================================\n",
    "\n",
    "def visualize_results(results, save_path=\"lesita_results.png\"):\n",
    "    \"\"\"Comprehensive visualization of results\"\"\"\n",
    "    print(\"üé® Creating visualization...\")\n",
    "    \n",
    "    fig, axes = plt.subplots(len(results), 6, figsize=(20, 4*len(results)))\n",
    "    if len(results) == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for idx, result in enumerate(results):\n",
    "        lr = result['lr'][0].numpy()\n",
    "        hr_gt = result['hr_gt'][0].numpy()\n",
    "        hr_pred = result['hr_pred'][0].detach().numpy()\n",
    "        guidance = result['guidance'][0].numpy()\n",
    "        sparse_u = result['sparse_u'].mean(dim=0).numpy()\n",
    "        sparse_z = result['sparse_z'].mean(dim=0).numpy()\n",
    "        \n",
    "        error_map = np.abs(hr_gt - hr_pred)\n",
    "        \n",
    "        # Plots\n",
    "        axes[idx, 0].imshow(lr, cmap='gray', vmin=0, vmax=1)\n",
    "        axes[idx, 0].set_title(f'LR Input (T2W)', fontsize=12)\n",
    "        axes[idx, 0].axis('off')\n",
    "        \n",
    "        axes[idx, 1].imshow(guidance, cmap='gray', vmin=0, vmax=1)\n",
    "        axes[idx, 1].set_title(f'Guidance (T1W)', fontsize=12)\n",
    "        axes[idx, 1].axis('off')\n",
    "        \n",
    "        axes[idx, 2].imshow(hr_gt, cmap='gray', vmin=0, vmax=1)\n",
    "        axes[idx, 2].set_title(f'Ground Truth', fontsize=12)\n",
    "        axes[idx, 2].axis('off')\n",
    "        \n",
    "        axes[idx, 3].imshow(hr_pred, cmap='gray', vmin=0, vmax=1)\n",
    "        axes[idx, 3].set_title(f'LeSITA Output\\n(PSNR: {result[\"psnr\"]:.2f}dB)', fontsize=12)\n",
    "        axes[idx, 3].axis('off')\n",
    "        \n",
    "        axes[idx, 4].imshow(error_map, cmap='hot', vmin=0, vmax=0.1)\n",
    "        axes[idx, 4].set_title(f'Error Map', fontsize=12)\n",
    "        axes[idx, 4].axis('off')\n",
    "        \n",
    "        sparse_diff = np.abs(sparse_u - sparse_z)\n",
    "        im = axes[idx, 5].imshow(sparse_diff, cmap='viridis')\n",
    "        axes[idx, 5].set_title(f'|Sparse U - Z|', fontsize=12)\n",
    "        axes[idx, 5].axis('off')\n",
    "        plt.colorbar(im, ax=axes[idx, 5], fraction=0.046, pad=0.04)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"üíæ Visualization saved: {save_path}\")\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN PIPELINE FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def setup_paths():\n",
    "    \"\"\"Setup and validate data paths\"\"\"\n",
    "    # Default paths - modify these for your setup\n",
    "    train_path = r\"D:\\Diploma Thesis\\MICCAI DATASETS\\LRx4_MStrain_flair_t1w_t2w_44_unnormalized.h5py\"\n",
    "    test_path = r\"D:\\Diploma Thesis\\MICCAI DATASETS\\LRx4_MStest_flair_t1w_t2w_unnormalized.h5py\"\n",
    "    \n",
    "    # Validate paths\n",
    "    if not os.path.exists(train_path):\n",
    "        print(f\"‚ùå Training file not found: {train_path}\")\n",
    "        return None, None\n",
    "    if not os.path.exists(test_path):\n",
    "        print(f\"‚ùå Test file not found: {test_path}\")\n",
    "        return None, None\n",
    "    \n",
    "    print(f\"‚úÖ Training file: {os.path.basename(train_path)} ({os.path.getsize(train_path)/1e6:.1f}MB)\")\n",
    "    print(f\"‚úÖ Test file: {os.path.basename(test_path)} ({os.path.getsize(test_path)/1e6:.1f}MB)\")\n",
    "    \n",
    "    return train_path, test_path\n",
    "\n",
    "def create_data_loaders(train_path, test_path, batch_size=32):\n",
    "    \"\"\"Create training and testing data loaders\"\"\"\n",
    "    print(\"üìä Creating data loaders...\")\n",
    "    \n",
    "    train_loader = get_dataloader(train_path, batch_size=batch_size, shuffle=True, augment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
